{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base url, and a lambda func to return url for a given year\n",
    "base_url = 'http://kenpom.com/index.php'\n",
    "url_year = lambda x: '%s?y=%s' % (base_url, str(x) if x != 2016 else base_url)\n",
    "\n",
    "# Years on kenpom's site (could also scrape this and \n",
    "# set as a list if you want to be more dynamic)\n",
    "years = range(2002, 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a method that parses a given year and spits out a raw dataframe\n",
    "def import_raw_year(year):\n",
    "    \"\"\"\n",
    "    Imports raw data from a ken pom year into a dataframe\n",
    "    \"\"\"\n",
    "    f = requests.get(url_year(year))\n",
    "    soup = BeautifulSoup(f.text)\n",
    "    table_html = soup.find_all('table', {'id': 'ratings-table'})\n",
    "\n",
    "    # Weird issue w/ <thead> in the html\n",
    "    # Prevents us from just using pd.read_html\n",
    "    # Let's find all the thead contents and just replace/remove them\n",
    "    # This allows us to easily put the table row data into a dataframe using panda\n",
    "    thead = table_html[0].find_all('thead')\n",
    "\n",
    "    table = table_html[0]\n",
    "    for x in thead:\n",
    "        table = str(table).replace(str(x), '')\n",
    "\n",
    "#    table = \"<table id='ratings-table'>%s</table>\" % table\n",
    "    df = pd.read_html(table)[0]\n",
    "    df['year'] = year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Import all the years into a singular dataframe\n",
    "df = None\n",
    "for x in years:\n",
    "    df = pd.concat( (df, import_raw_year(x)), axis=0) \\\n",
    "        if df is not None else import_raw_year(2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Column rename based off of original website\n",
    "df.columns = ['Rank', 'Team', 'Conference', 'W-L', 'Pyth', \n",
    "             'AdjustO', 'AdjustO Rank', 'AdjustD', 'AdjustD Rank',\n",
    "             'AdjustT', 'AdjustT Rank', 'Luck', 'Luck Rank', \n",
    "             'SOS Pyth', 'SOS Pyth Rank', 'SOS OppO', 'SOS OppO Rank',\n",
    "             'SOS OppD', 'SOS OppD Rank', 'NCSOS Pyth', 'NCSOS Pyth Rank', 'Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lambda that returns true if given string is a number and a valid seed number (1-16)\n",
    "valid_seed = lambda x: True if str(x).replace(' ', '').isdigit() \\\n",
    "                and int(x) > 0 and int(x) <= 16 else False\n",
    "\n",
    "# Use lambda to parse out seed/team\n",
    "df['Seed'] = df['Team'].apply(lambda x: x[-2:].replace(' ', '') \\\n",
    "                              if valid_seed(x[-2:]) else np.nan )\n",
    "\n",
    "df['Team'] = df['Team'].apply(lambda x: x[:-2] if valid_seed(x[-2:]) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split W-L column into wins and losses\n",
    "df['Wins'] = df['W-L'].apply(lambda x: int(re.sub('-.*', '', x)) )\n",
    "df['Losses'] = df['W-L'].apply(lambda x: int(re.sub('.*-', '', x)) )\n",
    "df.drop('W-L', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reorder columns just cause I'm OCD\n",
    "df=df[[ 'Year', 'Rank', 'Team', 'Conference', 'Wins', 'Losses', 'Seed','Pyth', \n",
    "             'AdjustO', 'AdjustO Rank', 'AdjustD', 'AdjustD Rank',\n",
    "             'AdjustT', 'AdjustT Rank', 'Luck', 'Luck Rank', \n",
    "             'SOS Pyth', 'SOS Pyth Rank', 'SOS OppO', 'SOS OppO Rank',\n",
    "             'SOS OppD', 'SOS OppD Rank', 'NCSOS Pyth', 'NCSOS Pyth Rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('kenpom.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
